{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NivratiKothari/Marketing-research-methods-Nivrati_Kothari-_-Jio-Institute/blob/main/Reddit_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFRsYjRlGSE5",
        "outputId": "25bfa251-cc8d-4dc8-87eb-dd4a12e3d247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching comments...\n",
            "Error: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=YOUR_VIDEO_ID&maxResults=50&textFormat=plainText&key=AIzaSyBfi3HVFk2J4CVfZqAbJaf118qJ0QCWeoM&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "No comments fetched.\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "# Download VADER Lexicon for better sentiment analysis (optional if using VADER)\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Define the API key and YouTube API service\n",
        "API_KEY = \"AIzaSyBfi3HVFk2J4CVfZqAbJaf118qJ0QCWeoM\"  # Replace with your Google Cloud API Key\n",
        "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
        "YOUTUBE_API_VERSION = 'v3'\n",
        "\n",
        "# Function to fetch YouTube video comments\n",
        "def fetch_comments(video_id, max_results=100):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "    comments = []\n",
        "    try:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part='snippet',\n",
        "            videoId=video_id,\n",
        "            maxResults=max_results,\n",
        "            textFormat='plainText'\n",
        "        ).execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append(comment)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    return comments\n",
        "\n",
        "# Sentiment Analysis Function\n",
        "def analyze_sentiments(comments):\n",
        "    sentiment_data = []\n",
        "    for comment in comments:\n",
        "        blob = TextBlob(comment)\n",
        "        sentiment_score = blob.sentiment.polarity  # Polarity: -1 (negative) to +1 (positive)\n",
        "        sentiment = 'Positive' if sentiment_score > 0 else 'Negative' if sentiment_score < 0 else 'Neutral'\n",
        "        sentiment_data.append({\n",
        "            'Comment': comment,\n",
        "            'Polarity': sentiment_score,\n",
        "            'Sentiment': sentiment\n",
        "        })\n",
        "    return pd.DataFrame(sentiment_data)\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == '__main__':\n",
        "    # Provide the YouTube video ID (can be found in the video URL)\n",
        "    video_id = 'YOUR_VIDEO_ID'  # Replace with the actual YouTube video ID\n",
        "    max_comments = 50  # Fetch up to 50 comments (YouTube API limit is 100 per request)\n",
        "\n",
        "    print(\"Fetching comments...\")\n",
        "    comments = fetch_comments(video_id, max_comments)\n",
        "\n",
        "    if comments:\n",
        "        print(f\"Fetched {len(comments)} comments. Analyzing sentiments...\")\n",
        "        sentiment_df = analyze_sentiments(comments)\n",
        "        print(sentiment_df)\n",
        "\n",
        "        # Save results to a CSV file\n",
        "        sentiment_df.to_csv('youtube_comments_sentiment_analysis.csv', index=False)\n",
        "        print(\"Sentiment analysis completed and saved to 'youtube_comments_sentiment_analysis.csv'.\")\n",
        "    else:\n",
        "        print(\"No comments fetched.\")\n"
      ]
    }
  ]
}